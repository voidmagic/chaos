{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficient Continuous Pareto Exploration in Multi-Task Learning\n",
    "\n",
    "Source code for ICML submission #640 \"Efficient Continuous Pareto Exploration in Multi-Task Learning\"\n",
    "\n",
    "This script generates Figure 5 in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import codecs\n",
    "import gzip\n",
    "import os\n",
    "import urllib\n",
    "import pickle\n",
    "import random\n",
    "from itertools import product\n",
    "from functools import partial\n",
    "from contextlib import contextmanager\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "import scipy.optimize\n",
    "from scipy.sparse.linalg import LinearOperator, minres\n",
    "from scipy import ndimage\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.legend_handler import HandlerTuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.nn.utils import parameters_to_vector, vector_to_parameters\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from common import *\n",
    "from min_norm_solver import find_min_norm_element\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random seed fixation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiMNIST(torch.utils.data.Dataset):\n",
    "    urls = [\n",
    "        'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',\n",
    "        'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',\n",
    "        'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',\n",
    "        'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz',\n",
    "    ]\n",
    "    raw_folder = 'raw'\n",
    "    processed_folder = 'processed'\n",
    "    training_file = 'training.pth'\n",
    "    test_file = 'test.pth'\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None, download=False):\n",
    "        self.root = Path(root)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.train = train  # training set or test set\n",
    "\n",
    "        if download:\n",
    "            self.download()\n",
    "\n",
    "        if not self._check_exists():\n",
    "            raise RuntimeError('Dataset not found.' +\n",
    "                               ' You can use download=True to download it')\n",
    "\n",
    "        if train:\n",
    "            self.data, self.labels_l, self.labels_r = torch.load(\n",
    "                self.root / self.processed_folder /self.training_file)\n",
    "        else:\n",
    "            self.data, self.labels_l, self.labels_r = torch.load(\n",
    "                self.root / self.processed_folder / self.test_file)\n",
    "\n",
    "        if transform is not None:\n",
    "            self.data = [self.transform(Image.fromarray(\n",
    "                img.numpy().astype(np.uint8), mode='L')) for img in self.data]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target_l, target_r = self.data[index], self.labels_l[index], self.labels_r[index]\n",
    "\n",
    "        return img, torch.stack([target_l, target_r])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _check_exists(self):\n",
    "        return (self.root / self.processed_folder / self.training_file).is_file() and \\\n",
    "            (self.root / self.processed_folder / self.test_file).is_file()\n",
    "\n",
    "    def download(self):\n",
    "        if self._check_exists():\n",
    "            return\n",
    "\n",
    "        # download files\n",
    "        (self.root / self.raw_folder).mkdir(parents=True, exist_ok=True)\n",
    "        (self.root / self.processed_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for url in self.urls:\n",
    "            print('Downloading ' + url)\n",
    "            data = urllib.request.urlopen(url)\n",
    "            filename = url.rpartition('/')[2]\n",
    "            file_path = self.root / self.raw_folder / filename\n",
    "            with open(file_path, 'wb') as f:\n",
    "                f.write(data.read())\n",
    "            with open(self.root / self.raw_folder / '.'.join(filename.split('.')[:-1]), 'wb') as out_f, \\\n",
    "                    gzip.GzipFile(file_path) as zip_f:\n",
    "                out_f.write(zip_f.read())\n",
    "            file_path.unlink()\n",
    "\n",
    "        # process and save as torch files\n",
    "        print('Processing...')\n",
    "        multi_mnist_ims, extension = self.read_image_file(\n",
    "            self.root / self.raw_folder / 'train-images-idx3-ubyte', shift_pix=4, rand_shift=True)\n",
    "        multi_mnist_labels_l, multi_mnist_labels_r = self.read_label_file(\n",
    "            self.root / self.raw_folder / 'train-labels-idx1-ubyte', extension)\n",
    "\n",
    "        tmulti_mnist_ims, textension = self.read_image_file(\n",
    "            self.root / self.raw_folder / 't10k-images-idx3-ubyte', shift_pix=4, rand_shift=True)\n",
    "        tmulti_mnist_labels_l, tmulti_mnist_labels_r = self.read_label_file(\n",
    "            self.root / self.raw_folder / 't10k-labels-idx1-ubyte', textension)\n",
    "\n",
    "        multi_mnist_training_set = (multi_mnist_ims, multi_mnist_labels_l, multi_mnist_labels_r)\n",
    "        multi_mnist_test_set = (tmulti_mnist_ims, tmulti_mnist_labels_l, tmulti_mnist_labels_r)\n",
    "\n",
    "        with open(self.root / self.processed_folder / self.training_file, 'wb') as f:\n",
    "            torch.save(multi_mnist_training_set, f)\n",
    "        with open(self.root / self.processed_folder / self.test_file, 'wb') as f:\n",
    "            torch.save(multi_mnist_test_set, f)\n",
    "        print('Done!')\n",
    "\n",
    "    def __repr__(self):\n",
    "        fmt_str = 'Dataset ' + self.__class__.__name__ + '\\n'\n",
    "        fmt_str += '    Number of datapoints: {}\\n'.format(self.__len__())\n",
    "        tmp = 'train' if self.train is True else 'test'\n",
    "        fmt_str += '    Split: {}\\n'.format(tmp)\n",
    "        fmt_str += '    Root Location: {}\\n'.format(self.root)\n",
    "        tmp = '    Transforms (if any): '\n",
    "        fmt_str += '{0}{1}\\n'.format(\n",
    "            tmp, self.transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
    "        tmp = '    Target Transforms (if any): '\n",
    "        fmt_str += '{0}{1}'.format(\n",
    "            tmp, self.target_transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
    "        return fmt_str\n",
    "\n",
    "    @staticmethod\n",
    "    def get_int(b):\n",
    "        return int(codecs.encode(b, 'hex'), 16)\n",
    "\n",
    "    @staticmethod\n",
    "    def read_label_file(path, extension):\n",
    "        with open(path, 'rb') as f:\n",
    "            data_1 = f.read()\n",
    "            assert MultiMNIST.get_int(data_1[:4]) == 2049\n",
    "        with open(path, 'rb') as f:\n",
    "            data_2 = f.read()\n",
    "            assert MultiMNIST.get_int(data_2[:4]) == 2049\n",
    "        length = MultiMNIST.get_int(data_1[4:8])\n",
    "        parsed_1 = np.frombuffer(data_1, dtype=np.uint8, offset=8)\n",
    "        parsed_2 = np.frombuffer(data_2, dtype=np.uint8, offset=8)\n",
    "        multi_labels_l = np.zeros(length, dtype=np.long)\n",
    "        multi_labels_r = np.zeros(length, dtype=np.long)\n",
    "        for im_id in range(length):\n",
    "            multi_labels_l[im_id] = parsed_1[im_id]\n",
    "            multi_labels_r[im_id] = parsed_2[extension[im_id]]\n",
    "        return (torch.from_numpy(multi_labels_l).view(-1).long(),\n",
    "                torch.from_numpy(multi_labels_r).view(-1).long())\n",
    "\n",
    "    @staticmethod\n",
    "    def read_image_file(path, shift_pix=4, rand_shift=True, rot_range=(0, 0), corot=True):\n",
    "        with open(path, 'rb') as f:\n",
    "            data_1 = f.read()\n",
    "            assert MultiMNIST.get_int(data_1[:4]) == 2051\n",
    "        with open(path, 'rb') as f:\n",
    "            data_2 = f.read()\n",
    "            assert MultiMNIST.get_int(data_2[:4]) == 2051\n",
    "        length = MultiMNIST.get_int(data_1[4:8])\n",
    "        num_rows = MultiMNIST.get_int(data_1[8:12])\n",
    "        num_cols = MultiMNIST.get_int(data_1[12:16])\n",
    "        parsed_1 = np.frombuffer(data_1, dtype=np.uint8, offset=16)\n",
    "        pv_1 = parsed_1.reshape(length, num_rows, num_cols)\n",
    "        parsed_2 = np.frombuffer(data_2, dtype=np.uint8, offset=16)\n",
    "        pv_2 = parsed_2.reshape(length, num_rows, num_cols)\n",
    "        multi_data = np.zeros((length, num_rows, num_cols))\n",
    "        extension = np.zeros(length, dtype=np.int32)\n",
    "        rights = np.random.permutation(length)\n",
    "        for left in range(length):\n",
    "            extension[left] = rights[left]\n",
    "            lim = pv_1[left, :, :]\n",
    "            rim = pv_2[rights[left], :, :]\n",
    "            if not rot_range[0] == rot_range[1] == 0:\n",
    "                if corot:\n",
    "                    rot_deg = random.randint(rot_range[0], rot_range[1])\n",
    "                    lim = ndimage.rotate(lim, rot_deg, reshape=False)\n",
    "                    rim = ndimage.rotate(rim, rot_deg, reshape=False)\n",
    "                else:\n",
    "                    rot_deg = random.randint(rot_range[0], rot_range[1])\n",
    "                    lim = ndimage.rotate(lim, rot_deg, reshape=False)\n",
    "                    rot_deg = random.randint(rot_range[0], rot_range[1])\n",
    "                    rim = ndimage.rotate(rim, rot_deg, reshape=False)\n",
    "            # in case of 100% overlapping\n",
    "            shift_pix1 = shift_pix2 = 0\n",
    "            if rand_shift:\n",
    "                if random.choice([True, False]):\n",
    "                    shift_pix1 = random.randint(0, shift_pix - 1)\n",
    "                    shift_pix2 = random.randint(0, shift_pix)\n",
    "                else:\n",
    "                    shift_pix1 = random.randint(0, shift_pix)\n",
    "                    shift_pix2 = random.randint(1, shift_pix)\n",
    "            new_im = np.zeros((36, 36))\n",
    "            new_im[shift_pix1:shift_pix1 + 28, shift_pix1:shift_pix1 + 28] += lim\n",
    "            new_im[shift_pix2 + 4:shift_pix2 + 4 + 28, shift_pix2 + 4:shift_pix2 + 4 + 28] += rim\n",
    "            new_im = np.clip(new_im, 0, 255)\n",
    "            multi_data_im = np.array(Image.fromarray(new_im).resize((28, 28), resample=Image.NEAREST))\n",
    "            multi_data[left, :, :] = multi_data_im\n",
    "        return torch.from_numpy(multi_data).view(length, num_rows, num_cols), extension\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset illustration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MultiMNIST(root='./MultiMNIST', train=True, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 5))\n",
    "plt.title('upper-left: {}\\nlower-right: {}'.format(\n",
    "    dataset[0][1][0], dataset[0][1][1]))\n",
    "plt.imshow(dataset[0][0].clone().detach().cpu().numpy(), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch initialization\n",
    "\n",
    "- working directory\n",
    "- device\n",
    "- dataloader\n",
    "- utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_root = Path('./MultiMNIST/checkpoints')\n",
    "ckpt_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "sgd_path = ckpt_root / 'sgd'\n",
    "sgd_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "mr_path = ckpt_root / 'minres'\n",
    "mr_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('Checkpoint root:', ckpt_root)\n",
    "print('SGD path:       ', sgd_path)\n",
    "print('MINRES path:    ', mr_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computating device initialization\n",
    "We remove all random state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')  # use default cuda device\n",
    "    import torch.backends.cudnn as cudnn  # make cuda deterministic\n",
    "    cudnn.benchmark = False\n",
    "    cudnn.deterministic = True\n",
    "else:\n",
    "    device = torch.device('cpu') # otherwise use cpu\n",
    "\n",
    "print('Current device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and test dataloader\n",
    "We use batch size of 256 for both training and test side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "trainset = MultiMNIST('./MultiMNIST', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=256, shuffle=True, drop_last=True, num_workers=0)\n",
    "\n",
    "testset = MultiMNIST('./MultiMNIST', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=256, shuffle=False, drop_last=False, num_workers=0)\n",
    "\n",
    "print('Training Dataset:')\n",
    "print(trainset)\n",
    "print()\n",
    "\n",
    "print('Test Dataset:')\n",
    "print(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions\n",
    "- evenly distributed weights\n",
    "- top-k accuracies\n",
    "- evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evenly_dist(num_weights, dim=2):\n",
    "    return [ret for ret in product(np.linspace(0.0, 1.0, num_weights + 2), repeat=dim) \\\n",
    "            if round(sum(ret), 6) == 1.0 and all(r not in (0.0, 1.0) for r in ret)]\n",
    "\n",
    "def topk_accuracies(logits, targets, ks=(1,)):\n",
    "    assert logits.dim() == 2\n",
    "    assert targets.dim() == 1\n",
    "    assert logits.size(0) == targets.size(0)\n",
    "\n",
    "    maxk = max(ks)\n",
    "    _, pred = logits.topk(maxk, dim=1, largest=True, sorted=True)\n",
    "    targets = targets.unsqueeze(1).expand_as(pred)\n",
    "    correct = pred.eq(targets).float()\n",
    "\n",
    "    accu_list = []\n",
    "    for k in ks:\n",
    "        accu = correct[:, :k].sum(1).mean()\n",
    "        accu_list.append(accu.item())\n",
    "    return accu_list\n",
    "\n",
    "def evaluate(network, dataloader, closures, topk_closures):\n",
    "    num_samples = 0\n",
    "    total_losses = np.zeros(len(closures))\n",
    "    total_top1s = np.zeros(len(closures))\n",
    "    with torch.no_grad():\n",
    "        network.train(False)\n",
    "        for images, targets in dataloader:\n",
    "            batch_size = len(images)\n",
    "            num_samples += batch_size\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "            logits = network(images)\n",
    "            losses = [c(network, logits, targets).item() for c in closures]\n",
    "            total_losses += batch_size * np.array(losses)\n",
    "            topks = [c(network, logits, targets) for c in topk_closures]\n",
    "            total_top1s += batch_size * np.array(topks)\n",
    "    total_losses /= num_samples\n",
    "    total_top1s /= num_samples\n",
    "    return total_losses, total_top1s\n",
    "\n",
    "print('Example of evenly_dist(num_weights=5, dim=2):')\n",
    "for i, combination in enumerate(evenly_dist(5, dim=2)):\n",
    "    print('{:d}: ('.format(i + 1) + ', '.join(['{:.3f}'.format(digit) for digit in combination]) + ')')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empirical Pareto front generation\n",
    "\n",
    "- hyper-parameters\n",
    "- network\n",
    "- loss function\n",
    "- optimizer\n",
    "- learning rate scheduler\n",
    "- inital state snapshot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-Parameters declaration\n",
    "- num of epochs\n",
    "- num of different weight combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "num_weights = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network definition\n",
    "\n",
    "We use a modified LeNet with a fully-connected layer for each task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, (5, 5))\n",
    "        self.conv2 = nn.Conv2d(10, 20, (5, 5))\n",
    "        self.fc1 = nn.Linear(20 * 4 * 4, 50)\n",
    "        self.fc3_1 = nn.Linear(50, 10)\n",
    "        self.fc3_2 = nn.Linear(50, 10)\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = [self.fc3_1(x), self.fc3_2(x)]\n",
    "        return x\n",
    "\n",
    "network = LeNet()\n",
    "network.to(device)\n",
    "\n",
    "print('Network:')\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function definition\n",
    "We use cross entropy loss for two tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "closures = [\n",
    "    lambda n, l, t: criterion(l[0], t[:, 0]),\n",
    "    lambda n, l, t: criterion(l[1], t[:, 1])\n",
    "]\n",
    "top1_closures = [\n",
    "    lambda n, l, t: topk_accuracies(l[0], t[:, 0], ks=(1,))[0],\n",
    "    lambda n, l, t: topk_accuracies(l[1], t[:, 1], ks=(1,))[0]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer definition\n",
    "We use SGD with learning rate of 0.01 and momentum of 0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(network.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate scheduler definition\n",
    "We use cosine annealing learning rate scheduler for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = CosineAnnealingLR(optimizer, num_epochs * len(trainloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snapshot for inital states\n",
    "\n",
    "The initial weights/optimizer/lr_scheduler are saved for further training (we removed **ALL** randomness)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_ckpt = {\n",
    "    'state_dict': network.state_dict(),\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "    'lr_scheduler': lr_scheduler.state_dict()\n",
    "}\n",
    "torch.save(init_ckpt, sgd_path / 'init.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's train it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, weight in enumerate(tqdm(evenly_dist(num_weights, 2), desc='Weight', leave=False)):\n",
    "    init_ckpt = torch.load(sgd_path / 'init.pth', map_location='cpu')  # load init snapshot\n",
    "    network.load_state_dict(init_ckpt['state_dict'])\n",
    "    optimizer.load_state_dict(init_ckpt['optimizer'])\n",
    "    lr_scheduler.load_state_dict(init_ckpt['lr_scheduler'])\n",
    "    with trange(num_epochs, desc='Epoch') as epoch_iter:\n",
    "        for epoch in epoch_iter:\n",
    "            network.train(True)\n",
    "            for images, targets in tqdm(trainloader, desc='Batch', leave=False):\n",
    "                images = images.to(device)\n",
    "                targets = targets.to(device)\n",
    "                logits = network(images)\n",
    "                losses = [c(network, logits, targets) for c in closures]\n",
    "                loss = sum(w * l for w, l in zip(weight, losses))\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                lr_scheduler.step()\n",
    "            eval_losses, eval_top1s = evaluate(network, testloader, closures, top1_closures)\n",
    "            epoch_iter.set_postfix(**{'acc-{:d}'.format(i + 1): top for i, top in enumerate(eval_top1s)})\n",
    "    ckpt = {\n",
    "        'state_dict': network.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'lr_scheduler': lr_scheduler.state_dict(),\n",
    "        'metrics': [eval_losses, eval_top1s]\n",
    "    }\n",
    "    torch.save(ckpt, sgd_path / '{:d}.pth'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD results illustration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "total_top1s = []\n",
    "for i in range(num_weights):\n",
    "    ckpt = torch.load(sgd_path / '{:d}.pth'.format(i), map_location='cpu')\n",
    "    losses, top1s = ckpt['metrics']\n",
    "    total_top1s.append(top1s)\n",
    "total_err1s = 100.0 * (1.0 - np.stack(total_top1s, axis=0).T)\n",
    "ax.scatter(*total_err1s, color='tab:red', marker='*', s=200, label='SGD')\n",
    "ax.set_xlabel('Upper-left Top-1 Error')\n",
    "ax.set_ylabel('Lower-right Top-1 Error')\n",
    "ax.grid(True)\n",
    "ax.set_axisbelow(True)\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MINRES initalization\n",
    "- hyper-parameters\n",
    "- dataloader\n",
    "- optimizer\n",
    "- Jacobian solver\n",
    "- linear operator\n",
    "- utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-Parameters declaration\n",
    "- num of steps\n",
    "- damping for linear solver\n",
    "- maxiter for MINRES\n",
    "- momentum for Jacobians and alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 10\n",
    "damping = 0.1\n",
    "maxiter = 50\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader definition\n",
    "\n",
    "We explore based on 2048 data samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr_dataloader = torch.utils.data.DataLoader(trainset, batch_size=2048, shuffle=True, drop_last=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer definition\n",
    "We use SGD with learning rate of 0.1 (**without** momentum for fair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr_optimizer = SGD(network.parameters(), lr=0.1)\n",
    "\n",
    "print(mr_optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jacobians solver definition\n",
    "We iterate over trainset to solve jacobian with respect to each task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jacobian_trainiter = iter(trainloader)\n",
    "def compute_jacobians(ratio=1.0):\n",
    "    global jacobian_trainiter\n",
    "    num_batches = int(len(trainloader) * ratio)\n",
    "    jacobians = None\n",
    "    for _ in range(num_batches):\n",
    "        try:\n",
    "            images, targets = next(jacobian_trainiter)\n",
    "        except StopIteration:\n",
    "            jacobian_trainiter = iter(trainloader)\n",
    "            images, targets = next(jacobian_trainiter)\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        logits = network(images)\n",
    "        losses = [c(network, logits, targets) for c in closures]\n",
    "        param_grads = [list(torch.autograd.grad(\n",
    "            l, network.parameters(), allow_unused=True,\n",
    "            retain_graph=True, create_graph=False)) for l in losses]\n",
    "        for param_grad in param_grads:\n",
    "            for i, (param_grad_module, param) in enumerate(zip(param_grad, network.parameters())):\n",
    "                if param_grad_module is None:\n",
    "                    param_grad[i] = torch.zeros_like(param)\n",
    "        sub_jacobians = torch.stack([parameters_to_vector(param_grad) for param_grad in param_grads], dim=0)\n",
    "        sub_jacobians.detach_()\n",
    "        if jacobians is None:\n",
    "            jacobians = sub_jacobians\n",
    "        else:\n",
    "            jacobians.add_(sub_jacobians)\n",
    "    jacobians.div_(num_batches)\n",
    "    return jacobians.clone().detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alpha solver definition\n",
    "We solve alpha by its analytical solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_alpha(jacobians):\n",
    "    sol, min_norm = find_min_norm_element(jacobians)\n",
    "    return sol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear operator for Hessian-vector product definition\n",
    "We warp Hessian-vector product into a linear operator to prevent explicit computation of Hessian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HVPLinearOperator(LinearOperator):\n",
    "    def __init__(self, dataloader):\n",
    "        network_size = sum(p.numel() for p in network.parameters())\n",
    "        shape = (network_size, network_size)\n",
    "        dtype = list(network.parameters())[0].detach().cpu().numpy().dtype\n",
    "\n",
    "        super(HVPLinearOperator, self).__init__(dtype, shape)\n",
    "\n",
    "        self.dataloader = dataloader\n",
    "        self.dataiter = iter(dataloader)\n",
    "\n",
    "        self.alpha_jacobians = None\n",
    "\n",
    "    def _get_jacobians(self):\n",
    "        try:\n",
    "            images, targets = next(self.dataiter)\n",
    "        except StopIteration:\n",
    "            self.dataiter = iter(self.dataloader)\n",
    "            images, targets = next(self.dataiter)\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        logits = network(images)\n",
    "        losses = [c(network, logits, targets) for c in closures]\n",
    "        \n",
    "        # Get jacobian with respect to each loss.\n",
    "        # `allow_unused=True` to get gradient from the unused tail.\n",
    "        #     It returns `None`, which will be filtered later.\n",
    "        # `retain_graph=True` to retain forward information for\n",
    "        #     second-time backward.\n",
    "        # `create_graph=True` to create computation graph for\n",
    "        #     second-order derivation.\n",
    "        param_grads = [list(torch.autograd.grad(\n",
    "            l, network.parameters(), allow_unused=True,\n",
    "            retain_graph=True, create_graph=True)) for l in losses]\n",
    "\n",
    "        # As metioned above, `allow_unused=True` leads to `None`s in\n",
    "        #     jacobian tuple. Now we replace it with a zero tensor.\n",
    "        for param_grad in param_grads:\n",
    "            for i, (param_grad_module, param) in enumerate(zip(param_grad, network.parameters())):\n",
    "                if param_grad_module is None:\n",
    "                    param_grad[i] = torch.zeros_like(param)\n",
    "                    \n",
    "        return torch.stack([parameters_to_vector(param_grad) for param_grad in param_grads], dim=0)\n",
    "\n",
    "    @contextmanager\n",
    "    def init(self, alpha):\n",
    "        try:\n",
    "            alpha = torch.as_tensor(alpha.astype(self.dtype), device=device).view(1, -1)\n",
    "            jacobians = self._get_jacobians()\n",
    "            self.alpha_jacobians = alpha.matmul(jacobians).squeeze()\n",
    "            yield self\n",
    "        finally:\n",
    "            self.alpha_jacobians = None\n",
    "\n",
    "    def _matvec_tensor(self, tensor):\n",
    "\n",
    "        # hvp = Hv\n",
    "        #     = dot(∂^2(f) / (∂x)^2, v)\n",
    "        #     = ∂/∂x(dot(v, ∂f/∂x))\n",
    "\n",
    "        # dot = dot(v, ∂f/∂x)\n",
    "        dot = self.alpha_jacobians.dot(tensor)\n",
    "        \n",
    "        # hvp = ∂/∂x(dot)\n",
    "        param_alphas_hvps = torch.autograd.grad(dot, network.parameters(), retain_graph=True)\n",
    "        alphas_hvps = parameters_to_vector([p.contiguous() for p in param_alphas_hvps])\n",
    "\n",
    "        if damping > 0.0:\n",
    "            alphas_hvps.add_(tensor, alpha=damping)\n",
    "        return alphas_hvps\n",
    "\n",
    "    def _matvec(self, x):\n",
    "        \"\"\"HVP matrix-vector multiplication handler.\n",
    "\n",
    "        If self is a linear operator of shape (N, N), then this method will\n",
    "        be called on a shape (N,) or (N, 1) ndarray, and should return a\n",
    "        shape (N,) or (N, 1) ndarray.\n",
    "\n",
    "        In our case, it computes alpha_hession @ x.\n",
    "        \"\"\"\n",
    "        tensor = torch.as_tensor(x.astype(self.dtype), device=device)\n",
    "        ret = self._matvec_tensor(tensor)\n",
    "        return ret.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions\n",
    "- assign parameter.grad from vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_grad(vector, normalize=True):\n",
    "    if normalize:\n",
    "        vector.div_(vector.norm())\n",
    "    offset = 0\n",
    "    for p in network.parameters():\n",
    "        numel = p.numel()\n",
    "        # view as to avoid deprecated pointwise semantics\n",
    "        p.grad = vector[offset:offset + numel].view_as(p.data).clone()\n",
    "        offset += numel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's explore it!\n",
    "Executing this section takes around 5 to 10 minutes depending on your GPU types. However, for the results reported in the paper and supplemental material, our training process is typically a lot faster than here because of the following reasons:\n",
    "\n",
    "- For reproducibility, we disable randomness in this script as much as we can. Therefore, parallalism on GPUs is not fully exploited;\n",
    "- We frequently evaluate and save the model inside the innermost loop, which creates a lot of overhead;\n",
    "- Since the MINRES implementation is from scipy and is on CPUs, calling `HVPLinearOperator` creates a lot of CPU-GPU communication. Ideally, a GPU implementation of MINRES could completely remove this communication and expedite the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_op_template = HVPLinearOperator(mr_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in trange(num_weights, desc='Weight', leave=False):\n",
    "    for col in trange(2, desc='Direction', leave=False):\n",
    "        \n",
    "        # load SGD starting point\n",
    "        init_ckpt = torch.load(sgd_path / '{:d}.pth'.format(i), map_location='cpu')\n",
    "        network.load_state_dict(init_ckpt['state_dict'])\n",
    "\n",
    "        # initalize momentum buffer\n",
    "        jacobians_buffer_tensor = compute_jacobians()\n",
    "        jacobians_buffer = jacobians_buffer_tensor.clone().detach().cpu().numpy()\n",
    "        alpha_buffer = compute_alpha(jacobians_buffer_tensor)\n",
    "        with trange(num_steps, desc='Step', leave=False) as step_iter:\n",
    "            for step in step_iter:\n",
    "                network.train(False)\n",
    "\n",
    "                # compute jacobians\n",
    "                jacobians_tensor = compute_jacobians(1.0 / 4.0)\n",
    "                jacobians = jacobians_tensor.clone().detach().cpu().numpy()\n",
    "                jacobians_buffer *= momentum\n",
    "                jacobians_buffer += (1 - momentum) * jacobians\n",
    "                jacobians = jacobians_buffer.copy()\n",
    "\n",
    "                # compute alpha\n",
    "                alpha = compute_alpha(jacobians_tensor)\n",
    "                alpha_buffer *= momentum\n",
    "                alpha_buffer += (1 - momentum) * alpha\n",
    "                alpha = alpha_buffer.copy()\n",
    "\n",
    "                # define rhs and x0\n",
    "                rhs = jacobians[col]\n",
    "                x0 = jacobians.mean(axis=0)\n",
    "                \n",
    "                # fill jacobians alpha rhs x0 to MINRES\n",
    "                with linear_op_template.init(alpha) as linear_op:\n",
    "                    results = minres(linear_op, rhs, x0=x0, maxiter=maxiter)\n",
    "                    d = torch.as_tensor(results[0].astype(linear_op.dtype), device=device)\n",
    "\n",
    "                # optimize\n",
    "                mr_optimizer.zero_grad()\n",
    "                assign_grad(d, normalize=True)\n",
    "                mr_optimizer.step()\n",
    "\n",
    "                eval_losses, eval_top1s = evaluate(network, testloader, closures, top1_closures)\n",
    "                step_iter.set_postfix(**{'acc-{:d}'.format(i + 1): top for i, top in enumerate(eval_top1s)})\n",
    "                ckpt = {\n",
    "                    'state_dict': network.state_dict(),\n",
    "                    'optimizer': mr_optimizer.state_dict(),\n",
    "                    'metrics': [eval_losses, eval_top1s]\n",
    "                }\n",
    "                save_path = mr_path / str(i) / str(col)\n",
    "                save_path.mkdir(parents=True, exist_ok=True)\n",
    "                torch.save(ckpt, save_path / '{:d}.pth'.format(step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "cmap = plt.get_cmap('autumn', num_weights)\n",
    "\n",
    "total_top1s = []\n",
    "for i in range(num_weights):\n",
    "    ckpt = torch.load(sgd_path / '{:d}.pth'.format(i), map_location='cpu')\n",
    "    losses, top1s = ckpt['metrics']\n",
    "    total_top1s.append(top1s)\n",
    "total_err1s = 100.0 * (1.0 - np.stack(total_top1s, axis=0).T)\n",
    "ax.scatter(*total_err1s, color=[cmap(i) for i in range(num_weights)],\n",
    "           marker='*', s=200, edgecolor='black', zorder=10)\n",
    "\n",
    "for i in range(num_weights):\n",
    "    total_top1s = []\n",
    "    for col in range(2):\n",
    "        for step in range(num_steps):\n",
    "            ckpt = torch.load(mr_path / str(i) / str(col) /  '{:d}.pth'.format(step), map_location='cpu')\n",
    "            losses, top1s = ckpt['metrics']\n",
    "            total_top1s.append(top1s)\n",
    "    total_err1s = 100.0 * (1.0 - np.stack(total_top1s, axis=0).T)\n",
    "    ax.scatter(*total_err1s, color=cmap(i), marker='o', s=30)\n",
    "\n",
    "ax.set_xlabel('Upper-left Top-1 Error')\n",
    "ax.set_ylabel('Lower-right Top-1 Error')\n",
    "ax.grid(True)\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "handles, labels = [], []\n",
    "handles.append(\n",
    "    tuple(ax.scatter([], [], color=cmap(i), marker='*', s=100, edgecolor='black') for i in range(1, 4)))\n",
    "labels.append('Start')\n",
    "\n",
    "handles.append(\n",
    "    tuple(ax.scatter([], [], color=cmap(i), marker='o', s=30) for i in range(1, 4)))\n",
    "labels.append('Ours')\n",
    "\n",
    "ax.legend(handles, labels, handler_map={tuple: HandlerTuple(None, 0)})\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
